{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1344719\n",
      "Test size: 336180\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "with open(\n",
    "    \"C:/Users/syafi/Desktop/syafiq-project/new classification task/model/saved_data/preprocessed_data.pkl\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)\n",
    "\n",
    "# Display train and test sizes\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sizes for experiments\n",
    "sample_sizes = [25, 50, 75, 100, 250, 500, 750, 1000, 2500, 5000, 7500, 10000, 20000, 30000, 40000, 50000]\n",
    "training_sizes = [20, 40, 60, 80, 200, 400, 600, 800, 2000, 4000, 6000, 8000, 16000, 24000, 32000, 40000]\n",
    "testing_sizes = [5, 10, 15, 20, 50, 100, 150, 200, 500, 1000, 1500, 2000, 4000, 6000, 8000, 10000]\n",
    "\n",
    "# Class labels for reporting\n",
    "class_labels = [\n",
    "    \"Atherosclerosis\",\n",
    "    \"Hypertension\",\n",
    "    \"Cardiovascular Disease (CVD)\",\n",
    "    \"Chronic Fatigue Syndrome (CFS)\",\n",
    "    \"Respiratory Disease (COPD or Asthma)\",\n",
    "    \"Stress-related Disorders\",\n",
    "    \"Arrhythmias\",\n",
    "    \"Healthy\",\n",
    "    \"Autonomic Dysfunction\",\n",
    "    \"Diabetes\",\n",
    "    \"Anaemia\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and return classification metrics\n",
    "def evaluate_model(model, X_test_subset, y_test_subset, class_labels):\n",
    "    predictions = model.predict(X_test_subset)\n",
    "    accuracy = accuracy_score(y_test_subset, predictions)\n",
    "    \n",
    "    # Generate dynamic class labels\n",
    "    unique_classes = np.unique(y_test_subset)\n",
    "    dynamic_labels = [\n",
    "        class_labels[i] for i in unique_classes\n",
    "    ]\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(\n",
    "        y_test_subset,\n",
    "        predictions, \n",
    "        target_names=dynamic_labels,\n",
    "        labels=unique_classes,\n",
    "        zero_division=0,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    return accuracy, report, predictions, unique_classes, dynamic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten classification report for easier analysis\n",
    "def flatten_classification_report(report, sample_size, train_size, test_size, accuracy):\n",
    "    flat_report = {\n",
    "        f\"{label}_{metric}\": value \n",
    "        for label, metrics in report.items()\n",
    "        if isinstance(metrics, dict) # Exclude keys like accuracy\n",
    "        for metric, value in metrics.items()\n",
    "    }\n",
    "    flat_report.update(\n",
    "        {\n",
    "            \"sample_size\": sample_size,\n",
    "            \"train_size\": train_size,\n",
    "            \"test_size\": test_size,\n",
    "            \"accuracy\": accuracy,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return flat_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def expand_test_set(X_test, y_test, repeat_factor):\n",
    "\n",
    "    Expand the test set by repeating each sample multiple times.\n",
    "\n",
    "    Args:\n",
    "        X_test (ndarray): Original test features.\n",
    "        y_test (ndarray): Original test labels.\n",
    "        repeat_factor (int): Number of times to repeat each test sample.\n",
    "\n",
    "    Returns:\n",
    "        Expanded test features and labels.\n",
    "\n",
    "    X_test_expanded = np.repeat(X_test, repeats=repeat_factor, axis=0)\n",
    "    y_test_expanded = np.repeat(y_test, repeats=repeat_factor)\n",
    "    return X_test_expanded, y_test_expanded\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping sample size 25 due to insufficient test_size (5) for all classes\n",
      "Skipping sample size 50 due to insufficient test_size (10) for all classes\n",
      "New best model found for sample size 75 with accuracy 0.2667\n",
      "New best model found for sample size 100 with accuracy 0.5000\n",
      "New best model found for sample size 250 with accuracy 0.9000\n",
      "New best model found for sample size 750 with accuracy 0.9333\n",
      "New best model found for sample size 7500 with accuracy 0.9400\n",
      "New best model found for sample size 30000 with accuracy 0.9412\n"
     ]
    }
   ],
   "source": [
    "# Container for results\n",
    "results = []\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_sample_size = 0\n",
    "\n",
    "# Iterate through sample, training, and testing sizes\n",
    "for sample_size, train_size, test_size in zip(\n",
    "    sample_sizes, training_sizes, testing_sizes\n",
    "):\n",
    "    # Perform stratified sampling on the training set\n",
    "    X_train_subset, _, y_train_subset, _ = train_test_split(\n",
    "        X_train, y_train, train_size=train_size, stratify=y_train, random_state=42\n",
    "    )\n",
    "\n",
    "    # Perform stratified sampling on the testing set\n",
    "    X_test_subset, _, y_test_subset, _ = train_test_split(\n",
    "        X_test, y_test, test_size=test_size, stratify=y_test, random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the Naive Bayes model\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy, report, predictions, unique_classes, dynamic_labels = evaluate_model(\n",
    "        nb_model, X_test_subset, y_test_subset, class_labels\n",
    "    )\n",
    "\n",
    "    # Print results for the current iteration\n",
    "    print(f\"\\nNaive Bayes Sample size {sample_size} - Accuracy: {accuracy:.4f}\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test_subset,\n",
    "            predictions,\n",
    "            target_names=dynamic_labels,\n",
    "            labels=unique_classes,\n",
    "            zero_division=0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Flatten report and store results\n",
    "    flat_report = flatten_classification_report(\n",
    "        report, sample_size, train_size, test_size, accuracy\n",
    "    )\n",
    "    results.append(flat_report)\n",
    "\n",
    "    # Update the best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = nb_model\n",
    "        best_sample_size = sample_size\n",
    "        print(\n",
    "            f\"New best model found for sample size {sample_size} with accuracy {accuracy:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "if best_model is not None:\n",
    "    best_model_file = f\"best_nb_model_sample_size_{best_sample_size}.pkl\"\n",
    "    with open(best_model_file, \"wb\") as model_file:\n",
    "        pickle.dump(best_model, model_file)\n",
    "    print(f\"\\nBest model saved as {best_model_file} with accuracy {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a CSV file for further analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"naive_bayes_results.csv\", index=False)\n",
    "print(\"\\nResults saved to 'naive_bayes_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display train and test set details\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Test size: {len(X_test)}\")\n",
    "print(\"\\nClass Distribution in Test Set:\")\n",
    "print(y_test.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydatascienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
